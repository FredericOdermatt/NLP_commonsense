{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Justers_Tesla.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjUTq1igOUOb"
      },
      "source": [
        "## Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxAV8C1pIqWG"
      },
      "source": [
        "import pandas as pd\r\n",
        "!nvidia-smi --query-gpu=timestamp,name,\\\r\n",
        "utilization.gpu,utilization.memory,\\\r\n",
        "memory.total,memory.free,memory.used --format=csv > gpu.csv\r\n",
        "display(pd.read_csv('gpu.csv', index_col=False))\r\n",
        "\r\n",
        "print('\\nGPU PRIO:\\nK90 < Tesla T4 < P100')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDWagrHVOkql"
      },
      "source": [
        "## Allow to SSH into this session\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C96tiJTXPBWB"
      },
      "source": [
        "# Install useful stuff\r\n",
        "! apt install --yes ssh screen nano htop ranger git > /dev/null\r\n",
        "# SSH setting\r\n",
        "! echo \"root:johlucfre\" | chpasswd\r\n",
        "! echo \"PasswordAuthentication yes\" > /etc/ssh/sshd_config\r\n",
        "! echo \"PermitUserEnvironment yes\" >> /etc/ssh/sshd_config\r\n",
        "! echo \"PermitRootLogin yes\" >> /etc/ssh/sshd_config\r\n",
        "! service ssh restart > /dev/null\r\n",
        "# Download ngrok\r\n",
        "! wget -q -c -nc https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\r\n",
        "! unzip -qq -n ngrok-stable-linux-amd64.zip\r\n",
        "# Run ngrok\r\n",
        "authtoken = \"1lsUxIKKMaw24jCJb8wgaDBgdX3_6fVMNEGJdEgwzc7ajkrKy\"\r\n",
        "get_ipython().system_raw('./ngrok authtoken $authtoken && ./ngrok tcp 22 &')\r\n",
        "! sleep 3\r\n",
        "# Get the address for SSH\r\n",
        "import requests\r\n",
        "from re import sub\r\n",
        "r = requests.get('http://localhost:4040/api/tunnels')\r\n",
        "str_ssh = r.json()['tunnels'][0]['public_url']\r\n",
        "str_ssh = sub(\"tcp://\", \"\", str_ssh)\r\n",
        "str_ssh = sub(\":\", \" -p \", str_ssh)\r\n",
        "str_ssh = \"ssh root@\" + str_ssh\r\n",
        "print(str_ssh)\r\n",
        "print('pw: johlucfre')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V002orkxOZ4Y"
      },
      "source": [
        "## Install Repo and Requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nebqb8SqKGwN"
      },
      "source": [
        "!ls\r\n",
        "!echo \"Current directory: $PWD\"\r\n",
        "![ -d \"NLP_commonsense\" ] && echo \"Directory NLP_commonsense exists.\" || git clone https://github.com/FredericOdermatt/NLP_commonsense.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3D-7TZhikqFI"
      },
      "source": [
        "pip install -r NLP_commonsense/requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfZjTFkhOfU2"
      },
      "source": [
        "## Train\r\n",
        "Note that to train on a batch-size of 16 you need to have a GPU with around 16GB of GPU RAM (see first cell)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axhEGx_blAtQ"
      },
      "source": [
        "# trained model stored at /content/$OUTDIR\r\n",
        "%cd /content/NLP_commonsense/JUSTers\r\n",
        "OUTDIR='/content/colab_trained'\r\n",
        "!mkdir -p $OUTDIR\r\n",
        "!ls\r\n",
        "!./train.sh $OUTDIR 16 5 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3VJGb7B6L-S"
      },
      "source": [
        "## Evaluation\r\n",
        "\r\n",
        "Calculate Scores for the output of the KaLM model stored at data100/kalm.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKqu8hYB5Nmf"
      },
      "source": [
        "%cd /content/NLP_commonsense/\r\n",
        "!./evaluate.sh data100/references_complete.csv data100/kalm.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a26HSeEH6agf"
      },
      "source": [
        "## Visualization\r\n",
        "\r\n",
        "Create plots showing correlations between scoring functions.\r\n",
        "**Note**: Before executing this cell you must evaluate the output using the cell above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3TW9a9Q6gcN"
      },
      "source": [
        "!python Visualization/visualize_scores.py\r\n",
        "from IPython.display import Image\r\n",
        "Image(filename='pairplot.png') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpA3OqMtXibW"
      },
      "source": [
        "## Copy to Leonhard\r\n",
        "\r\n",
        "Execute this command on leonhard and care to look at port number -p (execute cell below)\r\n",
        "\r\n",
        "`rsync -arvz -e 'ssh -p 17471' --progress root@4.tcp.ngrok.io:/content/colab_trained $HOME`\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RlrL9STXtix"
      },
      "source": [
        "print(str_ssh)\r\n",
        "print('pw: johlucfre')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}